predict_image.py

#!/usr/bin/env python3
"""
predict_image.py
Usage:
    python predict_image.py --model model_best.pth --image sample.jpg
"""
import argparse
from PIL import Image
import torch
from torchvision import transforms, models
import torch.nn as nn

def load_model(checkpoint_path, device):
    ck = torch.load(checkpoint_path, map_location=device)
    class_names = ck.get('class_names', None)
    num_classes = len(class_names) if class_names else ck['model_state']['fc.weight'].shape[0]
    model = models.resnet18(pretrained=False)
    in_features = model.fc.in_features
    model.fc = nn.Linear(in_features, num_classes)
    model.load_state_dict(ck['model_state'])
    model.to(device).eval()
    return model, class_names

def predict(model, class_names, img_path, device, img_size=224):
    tf = transforms.Compose([
        transforms.Resize(int(img_size*1.1)),
        transforms.CenterCrop(img_size),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),
    ])
    img = Image.open(img_path).convert('RGB')
    x = tf(img).unsqueeze(0).to(device)
    with torch.no_grad():
        out = model(x)
        probs = torch.nn.functional.softmax(out, dim=1)[0]
        topk = torch.topk(probs, k=min(5, len(class_names)))
        for idx, p in zip(topk.indices.cpu().numpy(), topk.values.cpu().numpy()):
            print(f"{class_names[idx]}: {p*100:.2f}%")

if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("--model", required=True)
    ap.add_argument("--image", required=True)
    ap.add_argument("--device", default="cuda" if torch.cuda.is_available() else "cpu")
    args = ap.parse_args()
    model, class_names = load_model(args.model, args.device)
    predict(model, class_names, args.image, args.device)
